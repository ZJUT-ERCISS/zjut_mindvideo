{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NonLocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[《Non-local Neural Networks》](https://arxiv.org/abs/1711.07971)发表于CVPR2018，用于作为处理动作分类的一种方法。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 算法原理简介\n",
    "\n",
    "<div align=center>\n",
    "<!-- <img src=./src/pic/nonlocal_block.png>  -->\n",
    "<img src=./pics/nonlocal_block.png> \n",
    "\n",
    "Figure 1 nonlocal_block </div>\n",
    "NonLocal是一个灵活的构建块，可以很容易地与卷积/循环层一起使用。它可以添加到深度神经网络的前面部分，不像fc层经常在最后使用。允许构建一个结合non-local信息和局部信息的更丰富的层次结构。论文中的nonlocal将某一位置的响应当做是一种从特征图谱所有位置的加权和来计算，这些位置既可以代表空间位置, 也可以代表时间, 时空等。Nonlocal其实和self-attention机制十分相关。在文中，为了能够将提出的nonlocal block当作一个组件自由的接入到各个神经网络中，作者设计的nonlocal 操作使得输入输出大小一致，具体实现公式如下：\n",
    " \n",
    " <div align=center>\n",
    "<img src=./pics/Formulation.png> \n",
    "\n",
    "Formulation</div>\n",
    "\n",
    "公式中，x代表输入，y代表输出，i和j分别代表输入的某个空间位置，xi是一个向量，维数跟x的channel数一样，f是一个计算任意两点相似关系的函数，g是一个映射函数，将一个点映射成一个向量，即该点的特征。为了计算输出层的一个点，需要将输入的每个点都考虑一遍，考虑的方式就和attention机制类似：过程中mask则是根据f函数给出，再和g映射函数相乘，最后求和，输出的某个点在原图上的attention。每个点以这样的方式计算，最后得到一个nonlocal的“attention map”。\n",
    "\n",
    "<div align=center>\n",
    "<img src=./pics/baseline_ResNet50_C2D.png> \n",
    "\n",
    "Table 1 baseline_ResNet50_C2D</div>\n",
    "表1显示了ResNet-50骨干网下的C2D基线。在这个存储库中，我们使用ResNet-50骨干网下的Inflated 3D ConvNet(I3D)。可以通过“inflating”内核将表1中的C2D模型转换为3D卷积模型。例如，一个2D的k×k内核可以被扩展为一个横跨t帧的3D t×k×k内核。我们添加5个块(3到res4, 2到res3，每隔一个残差块)。欲了解更多细节信息，请阅读论文[《Non-local Neural Networks》](https://arxiv.org/abs/1711.07971)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 环境准备\n",
    "```text\n",
    "git clone https://gitee.com/yanlq46462828/zjut_mindvideo.git\n",
    "cd zjut_mindvideo\n",
    "\n",
    "# Please first install mindspore according to instructions on the official website: https://www.mindspore.cn/install\n",
    "\n",
    "pip install -r requirements.txt\n",
    "pip install -e .\n",
    "```\n",
    "### 训练流程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor\n",
    "from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits\n",
    "from mindspore.nn.metrics import Accuracy\n",
    "\n",
    "from mindvideo.utils.check_param import Validator,Rel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据集加载\n",
    "\n",
    "将数据集下载到以下路径，或者根据自己需求改变路径即可。数据集下载链接：https://deepmind.com/research/open-source/kinetics\n",
    "通过基于VideoDataset编写的Kinetic400类来加载kinetic400数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/publicfile/kinetics-400/cls2index.json\n"
     ]
    }
   ],
   "source": [
    "from mindvideo.data.kinetics400 import Kinetic400\n",
    "# Data Pipeline.\n",
    "dataset = Kinetic400(path='/home/publicfile/kinetics-400',\n",
    "                    split=\"train\",\n",
    "                    shuffle=True,\n",
    "                    seq=32,\n",
    "                    seq_mode='interval',\n",
    "                    num_parallel_workers=1,\n",
    "                    batch_size=6,\n",
    "                    repeat_num=1,\n",
    "                    frame_interval=6)\n",
    "ckpt_save_dir = './nonlocal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 数据处理\n",
    "\n",
    "用VideoShortEdgeResize根据短边来进行Resize，再用VideoRandomCrop对Resize后的视频进行随机裁剪，再用VideoRandomHorizontalFlip根据概率对视频进行水平翻转，通过VideoRescale对视频进行缩放，利用VideoReOrder对维度进行变换，再用VideoNormalize进行归一化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(132676:140166743865152,MainProcess):2023-03-13-07:47:59.541.217 [mindspore/dataset/core/validator_helpers.py:804] 'Compose' from mindspore.dataset.transforms.py_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Compose' from mindspore.dataset.transforms instead.\n"
     ]
    }
   ],
   "source": [
    "from mindvideo.data.transforms import VideoRandomCrop, VideoRandomHorizontalFlip, VideoRescale\n",
    "from mindvideo.data.transforms import VideoNormalize, VideoShortEdgeResize, VideoReOrder\n",
    "# Data Pipeline.\n",
    "transforms = [VideoShortEdgeResize(size=256, interpolation='bicubic'),\n",
    "                VideoRandomCrop([224, 224]),\n",
    "                VideoRandomHorizontalFlip(0.5),\n",
    "                VideoRescale(),\n",
    "                VideoReOrder([3, 0, 1, 2]),\n",
    "                VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.255])]\n",
    "\n",
    "dataset.transform = transforms\n",
    "dataset_train = dataset.run()\n",
    "Validator.check_int(dataset_train.get_dataset_size(), 0, Rel.GT)\n",
    "step_size = dataset_train.get_dataset_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 网络构建\n",
    "1. Nonlocal最重要的结构是NonlocalBlockND（nn.Cell），该block包含四种成对相似度计算公式，以dot_product为例，主要通过三个Conv3d进行线性变换。NonlocalBlockND操作只需用到常用的卷积、矩阵相乘、加法、softmax等算子，用户可以非常方便的实现组网以构建模型。\n",
    "\n",
    "2. nonlocal3d包含backbone、avg_pool、flatten、head几部分组成。大致可以归纳为如下几点。\n",
    "第一部分：backbone部分是NLResInflate3D50（NLInflateResNet3D类），它是在NLInflateResNet3D结构中实现[3,4,6,3]规格的stage。而NLInflateResNet3D该结构是继承于ResNet3d50的结构，在ResNet3d50的[3,4,6,3]第2，3两个stage中的10层以每隔1层的方式插入一个NonlocalBlockND。\n",
    "第二部分：NLResInflate3D50输出到一个平均池化并flatten,\n",
    "第三部分：分类头。将flatten后的tensor输入到Dropdensehead进行分类，得到shape(N, NUM_CLASSES)的tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindvideo.models.nonlocal3d import nonlocal3d\n",
    "# Create model\n",
    "network = nonlocal3d(in_d=32,\n",
    "                     in_h=224,\n",
    "                     in_w=224,\n",
    "                     num_classes=400,\n",
    "                     keep_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindvideo.schedule.lr_schedule import warmup_step_lr\n",
    "# Set learning rate scheduler.\n",
    "lr = warmup_step_lr(lr=0.0003,\n",
    "                    lr_epochs=[1],\n",
    "                    steps_per_epoch=step_size,\n",
    "                    warmup_epochs=1,\n",
    "                    max_epoch=1,\n",
    "                    gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer.\n",
    "network_opt = nn.SGD(network.trainable_params(),\n",
    "                     lr,\n",
    "                     momentum=0.9,\n",
    "                     weight_decay=0.0001)\n",
    "# Define loss function.\n",
    "network_loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint for the network\n",
    "ckpt_config = CheckpointConfig(\n",
    "        save_checkpoint_steps=step_size,\n",
    "        keep_checkpoint_max=1)\n",
    "ckpt_callback = ModelCheckpoint(prefix='nonlocal_kinetics400',\n",
    "                                directory=ckpt_save_dir,\n",
    "                                config=ckpt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init the model.\n",
    "model = Model(network,\n",
    "            loss_fn=network_loss,\n",
    "            optimizer=network_opt,\n",
    "            metrics={\"Accuracy\": Accuracy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(132676:140166743865152,MainProcess):2023-03-13-07:54:00.444.33 [mindspore/dataset/core/validator_helpers.py:804] 'Compose' from mindspore.dataset.transforms.py_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Compose' from mindspore.dataset.transforms instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Start training `nonlocal_kinetics400`]\n",
      "================================================================================\n",
      "epoch: 1 step: 1, loss is 5.960698127746582\n",
      "epoch: 1 step: 2, loss is 6.26731538772583\n",
      "epoch: 1 step: 3, loss is 6.177163124084473\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132676/3121663089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mckpt_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLossMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             dataset_sink_mode=False)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[End of training `{}`]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nonlocal_kinetics400'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size, initial_epoch)\u001b[0m\n\u001b[1;32m   1047\u001b[0m                     \u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0msink_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msink_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m                     initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m         \u001b[0;31m# When it's Parameter Server training and using MindRT,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size, initial_epoch, valid_dataset, valid_frequency, valid_dataset_sink_mode)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_reuse_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_infos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"device_target\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"CPU\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 logger.info(\"The CPU cannot support dataset sink mode currently.\"\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36m_train_process\u001b[0;34m(self, epoch, train_dataset, list_callback, cb_params, initial_epoch, valid_infos)\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mlist_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mnext_element\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_helper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m                 \u001b[0mlen_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mnext_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_transfer_tensor_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/dataset_helper.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Note offload is applied inside _get_next() if applicable since get_next converts to output format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py\u001b[0m in \u001b[0;36m_get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffload_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_md_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNextAsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_md_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNextAsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin to train.\n",
    "print('[Start training `{}`]'.format('nonlocal_kinetics400'))\n",
    "print(\"=\" * 80)\n",
    "model.train(1,\n",
    "            dataset_train,\n",
    "            callbacks=[ckpt_callback, LossMonitor()],\n",
    "            dataset_sink_mode=False)\n",
    "print('[End of training `{}`]'.format('nonlocal_kinetics400'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 评估流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import context\n",
    "from mindspore.train.callback import Callback\n",
    "\n",
    "class PrintEvalStep(Callback):\n",
    "    \"\"\" print eval step \"\"\"\n",
    "    def step_end(self, run_context):\n",
    "        \"\"\" eval step \"\"\"\n",
    "        cb_params = run_context.original_args()\n",
    "        print(\"eval: {}/{}\".format(cb_params.cur_step_num, cb_params.batch_num))\n",
    "\n",
    "context.set_context(mode=context.GRAPH_MODE, device_target=\"GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/publicfile/kinetics-400/cls2index.json\n"
     ]
    }
   ],
   "source": [
    "from mindvideo.data.kinetics400 import Kinetic400\n",
    "\n",
    "dataset_eval = Kinetic400(path=\"/home/publicfile/kinetics-400\",\n",
    "                          split=\"val\",\n",
    "                          shuffle=True,\n",
    "                          seq=32,\n",
    "                          seq_mode='interval',\n",
    "                          num_parallel_workers=1,\n",
    "                          batch_size=1,\n",
    "                          frame_interval=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindvideo.data.transforms import VideoReOrder, VideoRescale, VideoNormalize\n",
    "from mindvideo.data.transforms import VideoCenterCrop, VideoShortEdgeResize\n",
    "\n",
    "transforms = [VideoShortEdgeResize(size=256, interpolation='bicubic'),\n",
    "              VideoCenterCrop([224, 224]),\n",
    "              VideoRescale(),\n",
    "              VideoReOrder([3, 0, 1, 2]),\n",
    "              VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.255])]\n",
    "dataset_eval.transform = transforms\n",
    "dataset_eval = dataset_eval.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn\n",
    "from mindspore.train import Model\n",
    "from mindspore.nn.loss import SoftmaxCrossEntropyWithLogits\n",
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "from mindvideo.models.nonlocal3d import nonlocal3d\n",
    "\n",
    " # Create model.\n",
    "network = nonlocal3d()\n",
    "\n",
    "\n",
    "# Define loss function.\n",
    "network_loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction=\"mean\")\n",
    "\n",
    "# Load pretrained model.\n",
    "param_dict = load_checkpoint(ckpt_file_name='/home/hcx/nonlocal_mindspore/scripts/nonlocal_output_0.0003/nonlocal-1_4975.ckpt')\n",
    "load_param_into_net(network, param_dict)\n",
    "\n",
    "# Define eval_metrics.\n",
    "eval_metrics = {'Loss': nn.Loss(),\n",
    "                'Top_1_Accuracy': nn.Top1CategoricalAccuracy(),\n",
    "                'Top_5_Accuracy': nn.Top5CategoricalAccuracy()}\n",
    "print_cb = PrintEvalStep()\n",
    "\n",
    "# Init the model.\n",
    "model = Model(network, loss_fn=network_loss, metrics=eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(132676:140166743865152,MainProcess):2023-03-13-07:55:07.379.431 [mindspore/train/model.py:1077] For PrintEvalStep callback, {'step_end'} methods may not be supported in later version, Use methods prefixed with 'on_train' or 'on_eval' instead when using customized callbacks.\n",
      "[WARNING] ME(132676:140166743865152,MainProcess):2023-03-13-07:55:07.381.857 [mindspore/dataset/core/validator_helpers.py:804] 'Compose' from mindspore.dataset.transforms.py_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Compose' from mindspore.dataset.transforms instead.\n",
      "[WARNING] ME(132676:140166743865152,MainProcess):2023-03-13-07:55:07.394.380 [mindspore/dataset/core/validator_helpers.py:804] 'Compose' from mindspore.dataset.transforms.py_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Compose' from mindspore.dataset.transforms instead.\n",
      "[WARNING] ME(132676:140166743865152,MainProcess):2023-03-13-07:55:07.398.446 [mindspore/dataset/core/validator_helpers.py:804] 'Compose' from mindspore.dataset.transforms.py_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Compose' from mindspore.dataset.transforms instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Start eval `nonlocal_kinetics400`]\n",
      "eval: 1/19877\n",
      "eval: 2/19877\n",
      "eval: 3/19877\n",
      "eval: 4/19877\n",
      "eval: 5/19877\n",
      "eval: 6/19877\n",
      "eval: 7/19877\n",
      "eval: 8/19877\n",
      "eval: 9/19877\n",
      "eval: 10/19877\n",
      "eval: 11/19877\n",
      "eval: 12/19877\n",
      "eval: 13/19877\n",
      "eval: 14/19877\n",
      "eval: 15/19877\n",
      "eval: 16/19877\n",
      "eval: 17/19877\n",
      "eval: 18/19877\n",
      "eval: 19/19877\n",
      "eval: 20/19877\n",
      "eval: 21/19877\n",
      "eval: 22/19877\n",
      "eval: 23/19877\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_132676/2813078720.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m result = model.eval(dataset_eval,\n\u001b[1;32m      4\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     dataset_sink_mode=False)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, valid_dataset, callbacks, dataset_sink_mode)\u001b[0m\n\u001b[1;32m   1424\u001b[0m                 \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_dataset_sink_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m                 \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eval_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;31m# When it's Parameter Server training and using MindRT,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36m_eval_process\u001b[0;34m(self, valid_dataset, list_callback, cb_params, add_eval_loss)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                                                   dataset_sink_mode=False)\n\u001b[1;32m   1326\u001b[0m         \u001b[0mlist_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_eval_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mnext_element\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset_helper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mcb_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_step_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0mlist_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_eval_step_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/train/dataset_helper.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Note offload is applied inside _get_next() if applicable since get_next converts to output format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/python-3.7.5/lib/python3.7/site-packages/mindspore/dataset/engine/iterators.py\u001b[0m in \u001b[0;36m_get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffload_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_md_to_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNextAsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_md_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetNextAsList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Begin to eval.\n",
    "print('[Start eval `{}`]'.format('nonlocal_kinetics400'))\n",
    "result = model.eval(dataset_eval,\n",
    "                    callbacks=[print_cb],\n",
    "                    dataset_sink_mode=False)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "[Gitee](https://gitee.com/yanlq46462828/zjut_mindvideo)\n",
    "\n",
    "[GitHub](https://github.com/Aprilkaka/nonlocal_mindspore)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
